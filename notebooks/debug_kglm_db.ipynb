{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d751497-c894-46e9-a17c-28ddd3dad6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import time\n",
    "# import fasttext\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54560c92-6ad8-44d6-8b05-bb72b4e32e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbourhood(collection, node_id, relation_id=None, tail_id=None):\n",
    "\n",
    "    neigh = []\n",
    "\n",
    "    # relation_id and tail_id excluded for test dataset\n",
    "    if relation_id == None or tail_id == None:\n",
    "        for doc in collection.find({'head': node_id}, {'_id': False}):\n",
    "            neigh.append(doc)\n",
    "\n",
    "        for doc in collection.find({'tail': node_id}, {'_id': False}):\n",
    "            doc['relation'] = 'inverse of ' + doc['relation']\n",
    "            neigh.append(doc)\n",
    "\n",
    "    # relation_id and tail_id included for train dataset verbalization to hide the target node\n",
    "    else:\n",
    "        for doc in collection.find({'head': node_id, 'tail': {'$ne': tail_id}, 'relation': {'$ne': relation_id}}, {'_id': False}):\n",
    "            neigh.append(doc)\n",
    "\n",
    "        for doc in collection.find({'tail': node_id, 'head': {'$ne': tail_id}, 'relation': {'$ne': relation_id}}, {'_id': False}):\n",
    "            doc['relation'] = 'inverse of ' + doc['relation']\n",
    "            neigh.append(doc)\n",
    "\n",
    "    return neigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6a53b92-3bbc-4597-a6c3-5ce746839410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('637ca5613c82960d48908165'),\n",
       " 'head': 'Q5142631',\n",
       " 'relation': 'P159',\n",
       " 'tail': 'Q3141'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = MongoClient('localhost', 15017)\n",
    "collection = client[\"KGLM-inductive\"]['train']\n",
    "collection.find_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02d0c6a7-c1ef-4392-ae8c-4f799ec9f03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity = 'Q5142631'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11ac9aec-5e9d-48d9-8d65-ebdd27908753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'head': 'Q5142631', 'relation': 'P159', 'tail': 'Q3141'},\n",
       " {'head': 'Q5142631', 'relation': 'P31', 'tail': 'Q1589009'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_neighbourhood(collection, entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e3225ce-b529-4371-b58a-71fc47e1f036",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient('localhost', 15017)\n",
    "collection = client[\"KGLM-inductive\"]['test']\n",
    "collection.find_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e968195-160b-49dd-8e7f-aa812e8028cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'train',\n",
       "  'type': 'collection',\n",
       "  'options': {},\n",
       "  'info': {'readOnly': False,\n",
       "   'uuid': Binary(b'M \\x11\\xa6\\x8a\\xc1N}\\xb9\\x0e\\xb7h\\xecEd]', 4)},\n",
       "  'idIndex': {'v': 2, 'key': {'_id': 1}, 'name': '_id_'}}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = client[\"KGLM-inductive\"]\n",
    "list(db.list_collections())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af37c845-7f88-41de-8181-62d2e4472ba3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d11c17-2b58-47ab-b1b6-2498b73f8ca0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f33bae84-86c1-4c78-9d79-3d36c8129f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# from megatron.data.dataset_utils import get_indexed_dataset_\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import horovod.torch as hvd\n",
    "from dotenv import load_dotenv\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, DistributedSampler, RandomSampler\n",
    "import datasets\n",
    "from huggingface_hub import hf_hub_download\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "from lm_experiments_tools import TrainerArgs\n",
    "from lm_experiments_tools.trainer_refactor import Trainer\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fab6d8c-c752-4191-937f-9b22909fa4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KGLMDataset(Dataset):\n",
    "    def __init__(self, port, db, collection, neighborhood=True):\n",
    "        self.client = MongoClient('localhost', port)\n",
    "        self.db_name = db\n",
    "        self.collection_name = collection\n",
    "        self.collection = self.client[db][collection]\n",
    "        self.length = self.client[self.db_name].command(\"collstats\", self.collection_name)['count']\n",
    "        self.neighborhood = neighborhood\n",
    "\n",
    "    def  __getitem__(self, idx):\n",
    "        item = {}\n",
    "        doc = self.collection.find_one({'_id': str(idx)})\n",
    "        print(doc)\n",
    "        \n",
    "        if self.neighborhood:\n",
    "            item[\"input\"] = doc['verbalization']\n",
    "        else:\n",
    "            verbalization = doc['verbalization']\n",
    "            inp = '[SEP]'.join(verbalization.split('[SEP]')[:2])\n",
    "            item[\"input\"] = inp\n",
    "            \n",
    "        item[\"outputs\"] = doc['target']\n",
    "        return item\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00abf7c1-5868-4c75-a8c0-83e5bd52e884",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cephfs/home/bulatov/bulatov/hvdenv/lib/python3.8/site-packages/cryptography/hazmat/backends/openssl/x509.py:14: CryptographyDeprecationWarning: This version of cryptography contains a temporary pyOpenSSL fallback path. Upgrade pyOpenSSL now.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('t5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "412a0e27-1f07-4cff-832d-3d3ad94fb5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Holder:\n",
    "    def __init__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9340dd7c-5cdb-4c51-9770-9f97ce1c3169",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Holder()\n",
    "args.target_seq_len = 512\n",
    "args.input_seq_len = 512\n",
    "args.input_prefix = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31a1dfb5-cae9-43b4-9fe9-2fb0946e4ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_plus_kwargs = {'truncation': True, 'padding': 'longest', 'pad_to_multiple_of': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86c90065-b7af-4bb3-807d-00c3081b52de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    # cut too long strings because they may slow down tokenization\n",
    "    inputs = [b['input'][:args.input_seq_len * 10] for b in batch]\n",
    "    print('inputs', inputs)\n",
    "    if 'outputs' in batch[0]:\n",
    "        # if we have more than 1 label per example (only in valid) take only one of them\n",
    "        # to compute loss on valid\n",
    "        labels = [b['outputs'][0][:args.target_seq_len * 10] for b in batch]\n",
    "    else:\n",
    "        labels = [b['output'][:args.target_seq_len * 10] for b in batch]\n",
    "    if args.input_prefix:\n",
    "        inputs = [args.input_prefix + inp for inp in inputs]\n",
    "    features = tokenizer.batch_encode_plus(list(inputs), max_length=args.input_seq_len, return_tensors='pt',\n",
    "                                           **encode_plus_kwargs)\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer.batch_encode_plus(list(labels), max_length=args.target_seq_len, return_tensors='pt',\n",
    "                                             **encode_plus_kwargs).input_ids\n",
    "    labels[labels == tokenizer.pad_token_id] = -100\n",
    "    features['labels'] = labels\n",
    "    # features['id'] = [b['id'] for b in batch]\n",
    "    if 'outputs' in batch[0]:\n",
    "        features['target_text'] = [b['outputs'] for b in batch]\n",
    "    else:\n",
    "        features['target_text'] = [b['output'] for b in batch]\n",
    "    if 'global_attention_mask' in features:\n",
    "        raise RuntimeError('What global attention mask for Longformer and LongformerEncoder-Decoder should be?')\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d866000a-ca53-4acb-942c-96d47a17f28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_PORTPORT = 15015\n",
    "train_dataset = KGLMDataset(DB_PORT, 'KGLM', 'train', neighborhood=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f8b708f-1b83-46ad-b9c0-d15444fe18e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '0',\n",
       " 'head': 'Q29387131',\n",
       " 'relation': 'P31',\n",
       " 'tail': 'Q5',\n",
       " 'verbalization': 'predict [SEP] Lalit Kumar Goel instance of [SEP] ',\n",
       " 'target': 'human'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.collection.find_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9e42844-a42b-41b9-b293-380851064ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = RandomSampler(train_dataset)\n",
    "kwargs = {'pin_memory': True, }\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2, sampler=train_sampler,\n",
    "                              collate_fn=collate_fn, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8dd53613-5f30-43a7-a4cb-dbd554de5db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'KGLM', 'sizeOnDisk': 5886840832, 'empty': False},\n",
       " {'name': 'KGLM-inductive', 'sizeOnDisk': 1347354624, 'empty': False},\n",
       " {'name': 'admin', 'sizeOnDisk': 40960, 'empty': False},\n",
       " {'name': 'config', 'sizeOnDisk': 73728, 'empty': False},\n",
       " {'name': 'local', 'sizeOnDisk': 73728, 'empty': False}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(client.list_databases())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82099c02-4f30-493d-b975-37734a09ef1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('637ca5613c82960d48908165'),\n",
       " 'head': 'Q5142631',\n",
       " 'relation': 'P159',\n",
       " 'tail': 'Q3141'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = MongoClient('localhost', 15017)\n",
    "collection = client[\"KGLM-inductive\"]['train']\n",
    "collection.find_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15440bdc-edeb-4fef-ac57-0f92d2aa4615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '0',\n",
       " 'head': 'Q29387131',\n",
       " 'relation': 'P31',\n",
       " 'tail': 'Q5',\n",
       " 'verbalization': 'predict [SEP] Lalit Kumar Goel instance of [SEP] ',\n",
       " 'target': 'human'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = MongoClient('localhost', 15017)\n",
    "collection = client[\"KGLM\"]['train']\n",
    "collection.find_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b8b9021-ef67-4757-9e3e-e8434feaf087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b = train_dataset[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39bb2390-cd73-4ec7-bbea-2477be5a564b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': '19599398', 'head': 'Q16325376', 'relation': 'P17', 'tail': 'Q794', 'verbalization': 'predict [SEP] Nazhvan Recreational Complex country [SEP] ', 'target': 'Iran'}\n",
      "{'_id': '20226282', 'head': 'Q3313042', 'relation': 'P2416', 'tail': 'Q165704', 'verbalization': 'predict [SEP] Miguel Ángel Sancho sports discipline competed in [SEP] sport athletics [SEP] country of citizenship Spain [SEP] instance of human [SEP] place of birth Valencia [SEP]', 'target': 'high jump'}\n",
      "inputs ['predict [SEP] Nazhvan Recreational Complex country ', 'predict [SEP] Miguel Ángel Sancho sports discipline competed in ']\n"
     ]
    }
   ],
   "source": [
    "gen = iter(train_dataloader)\n",
    "sample = next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76655218-38a7-4c99-b699-8fcc96802793",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c893966d-d7db-4a2b-b2fb-423d75519784",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad50ee8-b8e3-4e87-98c6-6c9d6d2e5bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer(sample['target_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10563c37-7988-46b8-9557-9ee25b917f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.batch_decode(sample['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7fd950-6810-4678-97db-b3e882bad158",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = [train_dataset[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96751f79-d258-4472-8a11-0370f68fc2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[936,   1]])\n"
     ]
    }
   ],
   "source": [
    "inputs = [b['input'][:args.input_seq_len * 10] for b in batch]\n",
    "if 'outputs' in batch[0]:\n",
    "    # if we have more than 1 label per example (only in valid) take only one of them\n",
    "    # to compute loss on valid\n",
    "    labels = [b['outputs'][:args.target_seq_len * 10] for b in batch]\n",
    "else:\n",
    "    labels = [b['output'][:args.target_seq_len * 10] for b in batch]\n",
    "if args.input_prefix:\n",
    "    inputs = [args.input_prefix + inp for inp in inputs]\n",
    "features = tokenizer.batch_encode_plus(list(inputs), max_length=args.input_seq_len, return_tensors='pt',\n",
    "                                       **encode_plus_kwargs)\n",
    "with tokenizer.as_target_tokenizer():\n",
    "    labels = tokenizer.batch_encode_plus(list(labels), max_length=args.target_seq_len, return_tensors='pt',\n",
    "                                         **encode_plus_kwargs).input_ids\n",
    "print(labels)\n",
    "labels[labels == tokenizer.pad_token_id] = -100\n",
    "features['labels'] = labels\n",
    "# features['id'] = [b['id'] for b in batch]\n",
    "if 'outputs' in batch[0]:\n",
    "    features['target_text'] = [b['outputs'] for b in batch]\n",
    "else:\n",
    "    features['target_text'] = [b['output'] for b in batch]\n",
    "if 'global_attention_mask' in features:\n",
    "    raise RuntimeError('What global attention mask for Longformer and LongformerEncoder-Decoder should be?')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12ad98b3-d633-4c17-a1ea-4ad6cf27a01a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[936, 1]], 'attention_mask': [[1, 1]]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [b['outputs'][:args.target_seq_len * 10] for b in batch]\n",
    "tokenizer.batch_encode_plus(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81df7f39-8f95-4207-a316-2ed823911c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['human']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "208faf15-8e6b-4a17-bcea-d9250019935b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.batch_decode(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5103d929-e272-41ef-9151-7818bb5ba575",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88a2247c-609e-414c-9aeb-07ddd6bef699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cpt_folder = \"/home/bulatov/bulatov/KGLM/runs/t5-small/lr5e-05_constant_with_warmup_adamw_wd1e-03_512-512_bs64_iters1000000_baseline/run_0/\"\n",
    "# cpt_folder = \"/share/home/export/rmt_internship/kglm/lr5e-05_constant_with_warmup_adamw_wd1e-03_512-512_bs64_iters1000000/run_0\"\n",
    "# cpt_folder = \"/home/bulatov/bulatov/KGLM/runs/t5-small/lr5e-05_constant_with_warmup_adamw_wd1e-03_512-512_bs32_iters1500000_baseline/run_0\"\n",
    "cpt_folder = \"/home/bulatov/bulatov/KGLM/runs/t5-small/lr5e-05_constant_with_warmup_adamw_wd1e-03_512-512_bs64_iters4000000/run_1/\"\n",
    "# cpt_folder = \"/home/bulatov/bulatov/KGLM/tests/runs/test_t5_pretrain/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "759d1700-14cb-4b23-9a60-6d12ea479323",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0b09620-3c96-4de4-a5e4-bef9b85f9281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls /share/home/export/rmt_internship/kglm/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d908621b-2d01-4334-9943-37ea5bee6ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cpt = os.path.join(cpt_folder, 'model_best.pth')\n",
    "config_path = os.path.join(cpt_folder, 'config.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "be8139c8-606b-4181-9fce-2b611087ae36",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpt = torch.load(model_cpt, map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b6c6a8e-3a00-4c29-b861-e5f99cf5df74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Config, AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a92efbd-f4b3-4a97-8266-a771ea8ba711",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = T5Config(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "696554a1-810a-4145-b5bb-c5e171bca639",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type encoder-decoder to instantiate a model of type t5. This is not supported for all configurations of models and can yield errors.\n"
     ]
    }
   ],
   "source": [
    "model_cfg = T5Config.from_pretrained(config_path)\n",
    "# model_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "43b3f36c-5a3a-4ce2-a751-767c1356786a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5Config {\n",
       "  \"_name_or_path\": \"t5-small\",\n",
       "  \"architectures\": [\n",
       "    \"T5WithLMHeadModel\"\n",
       "  ],\n",
       "  \"d_ff\": 2048,\n",
       "  \"d_kv\": 64,\n",
       "  \"d_model\": 512,\n",
       "  \"decoder_start_token_id\": 0,\n",
       "  \"dropout_rate\": 0.1,\n",
       "  \"eos_token_id\": 1,\n",
       "  \"feed_forward_proj\": \"relu\",\n",
       "  \"initializer_factor\": 1.0,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"layer_norm_epsilon\": 1e-06,\n",
       "  \"model_type\": \"t5\",\n",
       "  \"n_positions\": 512,\n",
       "  \"num_decoder_layers\": 6,\n",
       "  \"num_heads\": 8,\n",
       "  \"num_layers\": 6,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"relative_attention_num_buckets\": 32,\n",
       "  \"task_specific_params\": {\n",
       "    \"summarization\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"length_penalty\": 2.0,\n",
       "      \"max_length\": 200,\n",
       "      \"min_length\": 30,\n",
       "      \"no_repeat_ngram_size\": 3,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"summarize: \"\n",
       "    },\n",
       "    \"translation_en_to_de\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"max_length\": 300,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"translate English to German: \"\n",
       "    },\n",
       "    \"translation_en_to_fr\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"max_length\": 300,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"translate English to French: \"\n",
       "    },\n",
       "    \"translation_en_to_ro\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"max_length\": 300,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"translate English to Romanian: \"\n",
       "    }\n",
       "  },\n",
       "  \"transformers_version\": \"4.17.0\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 32128\n",
       "}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cfg = AutoConfig.from_pretrained('t5-small')\n",
    "# model_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "72b3f6d0-0f7d-46b4-8879-848018418143",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type encoder-decoder to instantiate a model of type t5. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cpt = os.path.join(cpt_folder, 'model_best.pth')\n",
    "config_path = os.path.join(cpt_folder, 'config.json')\n",
    "\n",
    "# model_cfg = AutoConfig.from_pretrained('t5-small')\n",
    "model_cfg = T5Config.from_pretrained(config_path)\n",
    "model = T5ForConditionalGeneration(config=model_cfg)\n",
    "\n",
    "cpt = torch.load(model_cpt, map_location='cpu')\n",
    "model.load_state_dict(cpt['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4d973e04-664e-41c5-84ae-2fdc67ad09c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(cpt['model_state_dict'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hvdenv",
   "language": "python",
   "name": "hvdenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
