{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f33bae84-86c1-4c78-9d79-3d36c8129f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "# from megatron.data.dataset_utils import get_indexed_dataset_\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "import torch\n",
    "import horovod.torch as hvd\n",
    "from dotenv import load_dotenv\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, DistributedSampler, RandomSampler\n",
    "import datasets\n",
    "from huggingface_hub import hf_hub_download\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "from lm_experiments_tools import TrainerArgs\n",
    "from lm_experiments_tools.trainer import Trainer\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "123265df-c2d5-4752-b9ad-1a2605194d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"../runs/t5-base/ilpc-large/lr5e-06_constant_with_warmup_adamw_wd1e-02_512-512_bs128_iters150000_pretrained_2sep_enum_nodesc/run_1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1c6f271-0cb7-4c8a-8c06-4183b4256234",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "669e1e13-31dc-4eb6-a49d-5f33752cb9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cephfs/home/bulatov/bulatov/hvdenv/lib/python3.8/site-packages/cryptography/hazmat/backends/openssl/x509.py:14: CryptographyDeprecationWarning: This version of cryptography contains a temporary pyOpenSSL fallback path. Upgrade pyOpenSSL now.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained('t5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80e4df01-9daa-4380-bbb3-2053e5221331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cpt = torch.load(model_path + 'model_best.pth', map_location='cpu')\n",
    "# model.load_state_dict(cpt['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01caf0db-8344-476e-bc1d-af3b709ff791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = '/home/bulatov/bulatov/datasets/ilpc22/small-valid.csv'\n",
    "# path = '/home/bulatov/bulatov/datasets/ilpc22/large_2sep/large_test.csv'\n",
    "# valid_path = '/home/bulatov/bulatov/datasets/ilpc22/large_2sep_enum/large_valid.csv'\n",
    "# test_path = '/home/bulatov/bulatov/datasets/ilpc22/large_2sep_enum/large_test.csv'\n",
    "\n",
    "valid_path = '/home/bulatov/bulatov/datasets/ilpc22/small_2sep_enum/small_valid.csv'\n",
    "test_path = '/home/bulatov/bulatov/datasets/ilpc22/small_2sep_enum/small_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd4cb9d0-0964-4224-92c2-bcac81b04a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KGLMLocalDataset(Dataset):\n",
    "    def __init__(self, path, neighborhood=True, description=True, sep='[SEP]', sep2=' [SEP-2] '):\n",
    "        self.df = pd.read_csv(path)\n",
    "        self.neighborhood = neighborhood\n",
    "        self.description = description\n",
    "        self.sep = sep\n",
    "        self.sep2 = sep2\n",
    "\n",
    "    def  __getitem__(self, idx):\n",
    "        item = {}\n",
    "        triplet = self.df.iloc[idx]\n",
    "        item[\"input\"] = triplet.verbalization\n",
    "        if not self.neighborhood:\n",
    "            item[\"input\"] = self.drop_neighborhood(item[\"input\"])\n",
    "        \n",
    "        item[\"outputs\"] = triplet['verbalized_tail']\n",
    "        if not self.description:\n",
    "            item[\"outputs\"] = self.drop_description(item[\"outputs\"])\n",
    "            \n",
    "        item[\"output_id\"] = triplet[\"tail\"]\n",
    "            \n",
    "        return item\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "            \n",
    "    \n",
    "    def drop_neighborhood(self, text):\n",
    "        return self.sep.join(text.split(self.sep)[:2]) + self.sep\n",
    "    \n",
    "    \n",
    "    def drop_description(self, text):\n",
    "        return text.split(self.sep2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15252e2d-00fb-4589-b632-bfe6acb2606b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = KGLMLocalDataset(path, neighborhood=True, description=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00abf7c1-5868-4c75-a8c0-83e5bd52e884",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('t5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "412a0e27-1f07-4cff-832d-3d3ad94fb5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Holder:\n",
    "    def __init__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9340dd7c-5cdb-4c51-9770-9f97ce1c3169",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Holder()\n",
    "args.target_seq_len = 512\n",
    "args.input_seq_len = 512\n",
    "args.input_prefix = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86c90065-b7af-4bb3-807d-00c3081b52de",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_attention_first_token = False  # should be True for LED\n",
    "encode_plus_kwargs = {'truncation': True, 'padding': 'longest', 'pad_to_multiple_of': 1}\n",
    "generate_kwargs = {}\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # print('batch', batch[0].keys(), batch[0]['input'])\n",
    "    # cut too long strings because they may slow down tokenization\n",
    "    inputs = [b['input'][:args.input_seq_len * 10] for b in batch]\n",
    "    if 'outputs' in batch[0]:\n",
    "        # if we have more than 1 label per example (only in valid) take only one of them\n",
    "        # to compute loss on valid\n",
    "        labels = [b['outputs'][:args.target_seq_len * 10] for b in batch]\n",
    "    else:\n",
    "        labels = [b['output'][:args.target_seq_len * 10] for b in batch]\n",
    "    if args.input_prefix:\n",
    "        inputs = [args.input_prefix + inp for inp in inputs]\n",
    "    features = tokenizer.batch_encode_plus(list(inputs), max_length=args.input_seq_len, return_tensors='pt',\n",
    "                                           **encode_plus_kwargs)\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer.batch_encode_plus(list(labels), max_length=args.target_seq_len, return_tensors='pt',\n",
    "                                             **encode_plus_kwargs).input_ids\n",
    "    labels[labels == tokenizer.pad_token_id] = -100\n",
    "    features['labels'] = labels\n",
    "    if 'outputs' in batch[0]:\n",
    "        features['target_text'] = [b['outputs'] for b in batch]\n",
    "    else:\n",
    "        features['target_text'] = [b['output'] for b in batch]\n",
    "    if 'output_id' in batch[0]:\n",
    "        features['output_id'] = [b['output_id'] for b in batch]\n",
    "    if 'global_attention_mask' in features:\n",
    "        raise RuntimeError('What global attention mask for Longformer and LongformerEncoder-Decoder should be?')\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7f8b708f-1b83-46ad-b9c0-d15444fe18e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64\n",
    "args.drop_neighborhood = False\n",
    "args.drop_description = True\n",
    "\n",
    "kwargs = {'pin_memory': True}#, 'num_workers': args.data_n_workers}\n",
    "valid_dataset = KGLMLocalDataset(valid_path, neighborhood=not args.drop_neighborhood, description=not args.drop_description)\n",
    "\n",
    "valid_sampler = RandomSampler(valid_dataset)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=bs, sampler=valid_sampler,\n",
    "                              collate_fn=collate_fn, **kwargs)\n",
    "\n",
    "\n",
    "test_dataset = KGLMLocalDataset(test_path, neighborhood=not args.drop_neighborhood, description=True)#not args.drop_description)\n",
    "test_sampler = RandomSampler(test_dataset)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=bs, sampler=test_sampler,\n",
    "                              collate_fn=collate_fn, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b9e42844-a42b-41b9-b293-380851064ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_sampler = RandomSampler(train_dataset)\n",
    "# kwargs = {'pin_memory': True, }\n",
    "# train_dataloader = DataLoader(train_dataset, batch_size=16, sampler=train_sampler,\n",
    "#                               collate_fn=collate_fn, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "39bb2390-cd73-4ec7-bbea-2477be5a564b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = iter(test_dataloader)\n",
    "sample = next(gen)\n",
    "\n",
    "target_text = sample.pop('target_text')\n",
    "output_id = sample.pop('output_id')\n",
    "labels = sample.pop('labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f80810ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_tokens(['[SEP]', '[SEP-2]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3ecc761d",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input_ids = model._shift_right(labels)\n",
    "with torch.no_grad():\n",
    "    out = model(**sample, decoder_input_ids=decoder_input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d0947e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input_ids = model._shift_right(labels)\n",
    "with torch.no_grad():\n",
    "    out = model(**sample, decoder_input_ids=decoder_input_ids)\n",
    "    \n",
    "sep2_id = tokenizer.encode('[SEP-2]')[0]\n",
    "\n",
    "lm_logits = out['logits']\n",
    "loss_fct = CrossEntropyLoss(ignore_index=-100, reduction='none')\n",
    "loss = loss_fct(lm_logits.view(-1, lm_logits.size(-1)), labels.view(-1))\n",
    "\n",
    "weight = 10\n",
    "entity_mask = torch.ones_like(labels)\n",
    "for row, start_ind in torch.nonzero(labels == sep2_id):\n",
    "    entity_mask[row, :start_ind] *= weight\n",
    "\n",
    "flat_entity_mask = entity_mask.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2350aac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sep2_id = tokenizer.encode('[SEP-2]')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0c05b0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = 10\n",
    "entity_mask = torch.ones_like(labels)\n",
    "for row, start_ind in torch.nonzero(labels == sep2_id):\n",
    "    entity_mask[row, :start_ind] *= weight\n",
    "\n",
    "flat_entity_mask = entity_mask.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "810033d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_loss = loss * flat_entity_mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d06a8d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([26.9937, 34.8106,  8.5109,  ...,  0.0000,  0.0000,  0.0000])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "03ae94a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([269.9374,  34.8106,   8.5109,  ...,   0.0000,   0.0000,   0.0000])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "00e53201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32101"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sep2_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a9942732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'predict [SEP] Roy Clark [SEP-2] American country music musician and performer cause of death [SEP] place of death Tulsa [SEP-2] county seat of Tulsa County, Oklahoma, United States [SEP] instrument banjo [SEP-2] musical instrument [SEP] record label Capitol Records [SEP-2] American record label; imprint of Capitol Records, Inc. [SEP] record label Four Star Records [SEP-2] record label [SEP]',\n",
       " 'outputs': 'pneumonia [SEP-2] inflammatory condition of the lung',\n",
       " 'output_id': 'Q12192'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40e7f3ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([704])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ba79546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.7404)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    out1 = model(**sample, labels = labels)\n",
    "out1['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b63a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9f942a-3ce3-4f6a-af04-f32fe5ce05d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['logits', 'past_key_values', 'encoder_last_hidden_state'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a9e400-3576-4264-8639-8e49d96c8d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.0198, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5693a25f-72dd-4707-9110-e10086c21ca7",
   "metadata": {},
   "source": [
    "### Calculate hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a95cd5-b014-4bf9-94c5-e5161d456926",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 17:36:24,282 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "2022-12-28 17:36:24,636 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import json\n",
    "import time\n",
    "\n",
    "\n",
    "class HitsCalculator:\n",
    "    def __init__(self, emb_model=SentenceTransformer('all-MiniLM-L6-v2'), drop_description=False):\n",
    "        self.emb_model = emb_model\n",
    "        if drop_description:\n",
    "            self.index=faiss.read_index(\"faiss/entities.index\")\n",
    "        else:\n",
    "            self.index=faiss.read_index(\"faiss/entities+desc.index\")\n",
    "            \n",
    "\n",
    "    def hits(self, outputs, labels, tokens_to_replace=(\" [SEP-2]\", \" [SEP-3]\")):\n",
    "        for token in tokens_to_replace:\n",
    "            outputs = list(map(lambda x: x.replace(token, \"\"), outputs))\n",
    "\n",
    "        vectors = self.emb_model.encode(outputs)\n",
    "        _, indices = self.index.search(vectors, 10)\n",
    "\n",
    "        hits = {\"Hits@1\": 0, \"Hits@3\": 0, \"Hits@5\": 0, \"Hits@10\": 0}\n",
    "\n",
    "        for i, label in enumerate(labels):\n",
    "            target = int(label[1:]) \n",
    "\n",
    "            if target == indices[i][0]:\n",
    "                hits['Hits@1'] += 1\n",
    "                hits['Hits@3'] += 1\n",
    "                hits['Hits@5'] += 1\n",
    "                hits['Hits@10'] += 1\n",
    "            \n",
    "            elif target in indices[i][:3]:\n",
    "                hits['Hits@3'] += 1\n",
    "                hits['Hits@5'] += 1\n",
    "                hits['Hits@10'] += 1\n",
    "\n",
    "            elif target in indices[i][:5]:\n",
    "                hits['Hits@5'] += 1\n",
    "                hits['Hits@10'] += 1\n",
    "            \n",
    "            elif target in indices[i][:10]:\n",
    "                hits['Hits@10'] += 1\n",
    "            \n",
    "        return { metric: hits[metric]/len(labels) for metric in hits.keys() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07008f88-9789-49eb-b4f6-f2a3cfe0fa89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d8aa574-1e60-4f84-bae1-64e67df102d9",
   "metadata": {},
   "source": [
    "### Debug Hits@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4903f42-1f56-420e-bf70-c0025591c01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_outputs = model.generate(sample['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a00d28e-c4e7-4942-a57b-70dc63a59405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad> musician [SEP-2] person who performs or composes music</s><pad><pad><pad><pad>',\n",
       " '<pad> UK [SEP-2] citizen [SEP-2] citizen in the Kingdom of the Netherlands',\n",
       " '<pad> Christian Church [SEP-2] consists of the Latin Church and 23 Eastern Catholic Churche',\n",
       " '<pad> Johann Sebastian Bach [SEP-2] 0 [SEP-2] 0 [S',\n",
       " '<pad> John James [SEP-2] inverse of genre John James [SEP-2] ',\n",
       " '<pad> John S. Kennedy [SEP-2] inverse of country of citizenship</s><pad><pad><pad>',\n",
       " '<pad> economist [SEP-2] a person who writes and publishes poetry</s><pad><pad>',\n",
       " '<pad> Paul Walker [SEP-2] inverse of languages spoken, written or signed John Wayne [',\n",
       " '<pad> Jean-François Pisier [SEP-2] French businessman, politician, and industrial',\n",
       " '<pad> William H. McMillan [SEP-2] inverse of educated at William',\n",
       " '<pad> [SEP-2] 0 president of the United States employer [SEP-2] ',\n",
       " '<pad> Johann Sebastian Bach [SEP-2] 0 [SEP-2] 0 [S',\n",
       " '<pad> Aziz Nesin [SEP-2] German writer, writer, and political column',\n",
       " '<pad> United States of America [SEP-2] federal republic in North America [SEP-2]',\n",
       " '<pad> French philosopher and philosopher [SEP-2] influenced by [SEP-2] influenced',\n",
       " '<pad> John S. Kennedy [SEP-2] inverse of country of citizenship</s><pad><pad><pad>']"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(gen_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78dba42-dc67-4563-865a-a126793eec3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'abc'.replace("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8085379c-bc4d-45ef-971c-d1cbcd40b48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import json\n",
    "import time\n",
    "\n",
    "\n",
    "class HitsCalculator:\n",
    "    def __init__(self, emb_model, index):\n",
    "        self.emb_model = emb_model\n",
    "        self.index = index\n",
    "\n",
    "    def hits(self, outputs, labels, tokens_to_replace=(\" [SEP-2]\", \" [SEP-3]\")):\n",
    "        for token in tokens_to_replace:\n",
    "            outputs = list(map(lambda x: x.replace(token, \"\"), outputs))\n",
    "\n",
    "        vectors = self.emb_model.encode(outputs)\n",
    "        _, indices = self.index.search(vectors, 10)\n",
    "\n",
    "        hits = {\"Hits@1\": 0, \"Hits@3\": 0, \"Hits@5\": 0, \"Hits@10\": 0}\n",
    "\n",
    "        for i, label in enumerate(labels):\n",
    "            target = int(label[1:]) \n",
    "\n",
    "            if target == indices[i][0]:\n",
    "                hits['Hits@1'] += 1\n",
    "                hits['Hits@3'] += 1\n",
    "                hits['Hits@5'] += 1\n",
    "                hits['Hits@10'] += 1\n",
    "            \n",
    "            elif target in indices[i][:3]:\n",
    "                hits['Hits@3'] += 1\n",
    "                hits['Hits@5'] += 1\n",
    "                hits['Hits@10'] += 1\n",
    "\n",
    "            elif target in indices[i][:5]:\n",
    "                hits['Hits@5'] += 1\n",
    "                hits['Hits@10'] += 1\n",
    "            \n",
    "            elif target in indices[i][:10]:\n",
    "                hits['Hits@10'] += 1\n",
    "            \n",
    "        return { metric: hits[metric]/len(labels) for metric in hits.keys() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9392df57-c8ac-4f22-a210-574d61ea9b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 16:51:35,898 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "2022-12-28 16:51:36,233 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device: cuda\n"
     ]
    }
   ],
   "source": [
    "index = faiss.read_index(\"../faiss/entities.index\") \n",
    "emb_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "hits_calculator = HitsCalculator(emb_model=emb_model, index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c279f1-eba7-4af7-8253-d2639b1b8b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = iter(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85db38c5-b7fd-45fa-a005-cee35a090493",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(gen)\n",
    "target_text = sample.pop('target_text')\n",
    "output_ids = sample.pop('output_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2307081d-b8b7-4165-9481-114e7fd0458d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nothing Records',\n",
       " 'United States of America',\n",
       " 'Climate Alliance',\n",
       " 'writer',\n",
       " 'Maria Rowohlt',\n",
       " 'Universal Postal Union',\n",
       " 'Albert Béguin',\n",
       " 'Germany',\n",
       " 'executive producer',\n",
       " 'Alberto Fujimori',\n",
       " 'Conrad Roland',\n",
       " 'Peter Capell',\n",
       " 'writer',\n",
       " 'voice',\n",
       " 'Svetlana Bondarchuk',\n",
       " 'John Cho']"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e7fa5d-dfe5-4f3b-8127-127bce95acb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Q2085119',\n",
       " 'Q30',\n",
       " 'Q1768108',\n",
       " 'Q36180',\n",
       " 'Q110685',\n",
       " 'Q17495',\n",
       " 'Q124251',\n",
       " 'Q183',\n",
       " 'Q1053574',\n",
       " 'Q133040',\n",
       " 'Q102980',\n",
       " 'Q97944',\n",
       " 'Q36180',\n",
       " 'Q17172850',\n",
       " 'Q4093262',\n",
       " 'Q312705']"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246c9568-09b3-4213-a545-d4bc1f7dfc08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ff8cdc718a84fd9a9e0aa10fcc004dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Hits@1': 1.0, 'Hits@3': 1.0, 'Hits@5': 1.0, 'Hits@10': 1.0}"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hits_calculator.hits(target_text, output_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63529ef-3a26-4359-818c-d2ce6e6538fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['musician [SEP-2] person who performs or composes music',\n",
       " 'UK [SEP-2] citizen [SEP-2] citizen in the Kingdom of the Netherlands',\n",
       " 'Christian Church [SEP-2] consists of the Latin Church and 23 Eastern Catholic Churche',\n",
       " 'Johann Sebastian Bach [SEP-2] 0 [SEP-2] 0 [S',\n",
       " 'John James [SEP-2] inverse of genre John James [SEP-2] ',\n",
       " 'John S. Kennedy [SEP-2] inverse of country of citizenship',\n",
       " 'economist [SEP-2] a person who writes and publishes poetry',\n",
       " 'Paul Walker [SEP-2] inverse of languages spoken, written or signed John Wayne [',\n",
       " 'Jean-François Pisier [SEP-2] French businessman, politician, and industrial',\n",
       " 'William H. McMillan [SEP-2] inverse of educated at William',\n",
       " '[SEP-2] 0 president of the United States employer [SEP-2] ',\n",
       " 'Johann Sebastian Bach [SEP-2] 0 [SEP-2] 0 [S',\n",
       " 'Aziz Nesin [SEP-2] German writer, writer, and political column',\n",
       " 'United States of America [SEP-2] federal republic in North America [SEP-2]',\n",
       " 'French philosopher and philosopher [SEP-2] influenced by [SEP-2] influenced',\n",
       " 'John S. Kennedy [SEP-2] inverse of country of citizenship']"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_outputs = tokenizer.batch_decode(gen_outputs, skip_special_tokens=True)\n",
    "model_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52a3658-140b-4466-82e2-9f2a9b1c80b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4cd9584bef74f9c9cc73290dc8bc839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Hits@1': 0.0, 'Hits@3': 0.0, 'Hits@5': 0.0, 'Hits@10': 0.0}"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hits_calculator.hits(model_outputs, output_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4bc91d-d34d-445b-a109-c39353873d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 10]), torch.Size([2, 19]))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['labels'].shape, gen_outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9480a3-4d25-46b6-b909-69c1d6e48bd9",
   "metadata": {},
   "source": [
    "### weigh loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2846e65a-6811-4341-978e-bdccaed149c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['loss', 'logits', 'past_key_values', 'encoder_last_hidden_state'])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb078159-bae9-49ef-80db-045cdb835210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10, 32128])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a967b8-6833-416f-986a-c663880a06f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_logits = out.logits\n",
    "labels = sample['labels']\n",
    "\n",
    "loss_fct = CrossEntropyLoss(ignore_index=-100)\n",
    "loss = loss_fct(lm_logits.view(-1, lm_logits.size(-1)), labels.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaa0ac0-79a0-48d4-8765-b437e00acf03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 10, 32128]), torch.Size([2, 10]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_logits.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e5b83c-5cc4-4cb1-b4ff-dd6e98935c49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([20, 32128]), torch.Size([20]))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_logits.view(-1, lm_logits.size(-1)).shape, labels.view(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10d91aa-60ef-492c-b38a-fc5b50137763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 32128]), torch.Size([2]))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_logits[:, 0].view(-1, lm_logits.size(-1)).shape, labels[:, 0].view(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7652a01-360a-48ed-a2c1-7af84489f471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32128])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_logits[0, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70638c3-28c3-43d4-9e05-922ee885bc2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10001])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:1, :1].view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ca961c-fa7f-4e03-931a-796cd91a6d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "loss_fct = CrossEntropyLoss(ignore_index=-100, reduce=False)\n",
    "loss_fct(lm_logits.view(-1, lm_logits.size(-1)), labels.view(-1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6037186a-7725-4713-a7af-463f16ba298d",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [81]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mloss_fct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlm_logits\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cephfs/home/bulatov/bulatov/hvdenv/lib/python3.8/site-packages/torch/nn/modules/module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 727\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    729\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    730\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    731\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[0;32m/cephfs/home/bulatov/bulatov/hvdenv/lib/python3.8/site-packages/torch/nn/modules/loss.py:961\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 961\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cephfs/home/bulatov/bulatov/hvdenv/lib/python3.8/site-packages/torch/nn/functional.py:2468\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2466\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2467\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 2468\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nll_loss(\u001b[43mlog_softmax\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, target, weight, \u001b[38;5;28;01mNone\u001b[39;00m, ignore_index, \u001b[38;5;28;01mNone\u001b[39;00m, reduction)\n",
      "File \u001b[0;32m/cephfs/home/bulatov/bulatov/hvdenv/lib/python3.8/site-packages/torch/nn/functional.py:1605\u001b[0m, in \u001b[0;36mlog_softmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1603\u001b[0m     dim \u001b[38;5;241m=\u001b[39m _get_softmax_dim(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog_softmax\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim(), _stacklevel)\n\u001b[1;32m   1604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1605\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_softmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1606\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1607\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mlog_softmax(dim, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "loss_fct(lm_logits[0, 0], labels[0, :1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bd524a-40ed-4cad-b999-bf157af10761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.0220, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02111c1-9570-4625-92df-d5cb3d9750f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c893966d-d7db-4a2b-b2fb-423d75519784",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['labels']a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad50ee8-b8e3-4e87-98c6-6c9d6d2e5bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer(sample['target_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10563c37-7988-46b8-9557-9ee25b917f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.batch_decode(sample['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7fd950-6810-4678-97db-b3e882bad158",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = [train_dataset[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96751f79-d258-4472-8a11-0370f68fc2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[936,   1]])\n"
     ]
    }
   ],
   "source": [
    "inputs = [b['input'][:args.input_seq_len * 10] for b in batch]\n",
    "if 'outputs' in batch[0]:\n",
    "    # if we have more than 1 label per example (only in valid) take only one of them\n",
    "    # to compute loss on valid\n",
    "    labels = [b['outputs'][:args.target_seq_len * 10] for b in batch]\n",
    "else:\n",
    "    labels = [b['output'][:args.target_seq_len * 10] for b in batch]\n",
    "if args.input_prefix:\n",
    "    inputs = [args.input_prefix + inp for inp in inputs]\n",
    "features = tokenizer.batch_encode_plus(list(inputs), max_length=args.input_seq_len, return_tensors='pt',\n",
    "                                       **encode_plus_kwargs)\n",
    "with tokenizer.as_target_tokenizer():\n",
    "    labels = tokenizer.batch_encode_plus(list(labels), max_length=args.target_seq_len, return_tensors='pt',\n",
    "                                         **encode_plus_kwargs).input_ids\n",
    "print(labels)\n",
    "labels[labels == tokenizer.pad_token_id] = -100\n",
    "features['labels'] = labels\n",
    "# features['id'] = [b['id'] for b in batch]\n",
    "if 'outputs' in batch[0]:\n",
    "    features['target_text'] = [b['outputs'] for b in batch]\n",
    "else:\n",
    "    features['target_text'] = [b['output'] for b in batch]\n",
    "if 'global_attention_mask' in features:\n",
    "    raise RuntimeError('What global attention mask for Longformer and LongformerEncoder-Decoder should be?')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ad98b3-d633-4c17-a1ea-4ad6cf27a01a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[936, 1]], 'attention_mask': [[1, 1]]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [b['outputs'][:args.target_seq_len * 10] for b in batch]\n",
    "tokenizer.batch_encode_plus(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81df7f39-8f95-4207-a316-2ed823911c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['human']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208faf15-8e6b-4a17-bcea-d9250019935b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.batch_decode(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5103d929-e272-41ef-9151-7818bb5ba575",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a2247c-609e-414c-9aeb-07ddd6bef699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cpt_folder = \"/home/bulatov/bulatov/KGLM/runs/t5-small/lr5e-05_constant_with_warmup_adamw_wd1e-03_512-512_bs64_iters1000000_baseline/run_0/\"\n",
    "# cpt_folder = \"/share/home/export/rmt_internship/kglm/lr5e-05_constant_with_warmup_adamw_wd1e-03_512-512_bs64_iters1000000/run_0\"\n",
    "# cpt_folder = \"/home/bulatov/bulatov/KGLM/runs/t5-small/lr5e-05_constant_with_warmup_adamw_wd1e-03_512-512_bs32_iters1500000_baseline/run_0\"\n",
    "cpt_folder = \"/home/bulatov/bulatov/KGLM/runs/t5-small/lr5e-05_constant_with_warmup_adamw_wd1e-03_512-512_bs64_iters4000000/run_1/\"\n",
    "# cpt_folder = \"/home/bulatov/bulatov/KGLM/tests/runs/test_t5_pretrain/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759d1700-14cb-4b23-9a60-6d12ea479323",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b09620-3c96-4de4-a5e4-bef9b85f9281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls /share/home/export/rmt_internship/kglm/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d908621b-2d01-4334-9943-37ea5bee6ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cpt = os.path.join(cpt_folder, 'model_best.pth')\n",
    "config_path = os.path.join(cpt_folder, 'config.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8139c8-606b-4181-9fce-2b611087ae36",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpt = torch.load(model_cpt, map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6c6a8e-3a00-4c29-b861-e5f99cf5df74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Config, AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a92efbd-f4b3-4a97-8266-a771ea8ba711",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = T5Config(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696554a1-810a-4145-b5bb-c5e171bca639",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type encoder-decoder to instantiate a model of type t5. This is not supported for all configurations of models and can yield errors.\n"
     ]
    }
   ],
   "source": [
    "model_cfg = T5Config.from_pretrained(config_path)\n",
    "# model_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b3f36c-5a3a-4ce2-a751-767c1356786a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5Config {\n",
       "  \"_name_or_path\": \"t5-small\",\n",
       "  \"architectures\": [\n",
       "    \"T5WithLMHeadModel\"\n",
       "  ],\n",
       "  \"d_ff\": 2048,\n",
       "  \"d_kv\": 64,\n",
       "  \"d_model\": 512,\n",
       "  \"decoder_start_token_id\": 0,\n",
       "  \"dropout_rate\": 0.1,\n",
       "  \"eos_token_id\": 1,\n",
       "  \"feed_forward_proj\": \"relu\",\n",
       "  \"initializer_factor\": 1.0,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"layer_norm_epsilon\": 1e-06,\n",
       "  \"model_type\": \"t5\",\n",
       "  \"n_positions\": 512,\n",
       "  \"num_decoder_layers\": 6,\n",
       "  \"num_heads\": 8,\n",
       "  \"num_layers\": 6,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"relative_attention_num_buckets\": 32,\n",
       "  \"task_specific_params\": {\n",
       "    \"summarization\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"length_penalty\": 2.0,\n",
       "      \"max_length\": 200,\n",
       "      \"min_length\": 30,\n",
       "      \"no_repeat_ngram_size\": 3,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"summarize: \"\n",
       "    },\n",
       "    \"translation_en_to_de\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"max_length\": 300,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"translate English to German: \"\n",
       "    },\n",
       "    \"translation_en_to_fr\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"max_length\": 300,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"translate English to French: \"\n",
       "    },\n",
       "    \"translation_en_to_ro\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"max_length\": 300,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"translate English to Romanian: \"\n",
       "    }\n",
       "  },\n",
       "  \"transformers_version\": \"4.17.0\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 32128\n",
       "}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cfg = AutoConfig.from_pretrained('t5-small')\n",
    "# model_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b3f6d0-0f7d-46b4-8879-848018418143",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type encoder-decoder to instantiate a model of type t5. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cpt = os.path.join(cpt_folder, 'model_best.pth')\n",
    "config_path = os.path.join(cpt_folder, 'config.json')\n",
    "\n",
    "# model_cfg = AutoConfig.from_pretrained('t5-small')\n",
    "model_cfg = T5Config.from_pretrained(config_path)\n",
    "model = T5ForConditionalGeneration(config=model_cfg)\n",
    "\n",
    "cpt = torch.load(model_cpt, map_location='cpu')\n",
    "model.load_state_dict(cpt['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d973e04-664e-41c5-84ae-2fdc67ad09c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(cpt['model_state_dict'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hvdenv",
   "language": "python",
   "name": "hvdenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
